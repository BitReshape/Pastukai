{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BeEyhgQWMvAp"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aYtP6p_sM-4n"
   },
   "outputs": [],
   "source": [
    "!mkdir -p \"/content/drive/MyDrive/uni/pastukai/temp\"\n",
    "!mkdir -p \"/content/drive/MyDrive/uni/pastukai/data\"\n",
    "!ls \"/content/drive/MyDrive/uni/pastukai\"\n",
    "%cd \"/content/drive/MyDrive/uni/pastukai/temp\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IxtHsFs1NCjz"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "DATASET_DIR=\"/content/drive/MyDrive/uni/pastukai/temp/dataset/\"\n",
    "\n",
    "if [ ! -f \"ISIC_2019_Training_Input.zip\" ]; then\n",
    "    echo \"Downloading Training Data ...\"\n",
    "    wget --show-progress --progress=bar:force https://isic-challenge-data.s3.amazonaws.com/2019/ISIC_2019_Training_Input.zip -O ISIC_2019_Training_Input.zip\n",
    "fi\n",
    "\n",
    "echo \"Unpacking ISIC_2019_Training_Input.zip ...\"\n",
    "unzip -q -j ISIC_2019_Training_Input.zip -d $DATASET_DIR\n",
    "\n",
    "# Number of files in dataset folder.\n",
    "ls $DATASET_DIR | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2P-inQplNELJ"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "DATASET_DIR=\"/content/drive/MyDrive/uni/pastukai/temp/dataset/\"\n",
    "\n",
    "if [ -d $DATASET_DIR ] && [ $(ls -1 $DATASET_DIR | wc -l) -eq 25333 ]; then\n",
    "    echo \"Successfully built the dataset\"\n",
    "else\n",
    "    echo \"Error when building the dataset\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vO-rsR0qNME7"
   },
   "source": [
    "**Split data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "u5k8_TM4NGmg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.util import random_noise\n",
    "from skimage import img_as_ubyte, img_as_float\n",
    "import random\n",
    "\n",
    "\n",
    "def get_classification(data_series):\n",
    "    '''\n",
    "\n",
    "    :param data_series: dataserie containing the one hotencoding\n",
    "    :return: classification as string\n",
    "    '''\n",
    "    classification = None\n",
    "    for index, value in data_series.items():\n",
    "        if value == 1.0:\n",
    "            classification = index\n",
    "    return classification\n",
    "\n",
    "\n",
    "# Augmentation functions\n",
    "def flip_image(img, vflip=False, hflip=False):\n",
    "    '''\n",
    "    Flip image vertically or horizontally\n",
    "    :param img: ndarray, BGR image\n",
    "    :param vflip: bool if vertically flip\n",
    "    :param hflip: bool if horizontally flip\n",
    "    :return: ndarray, BGR image\n",
    "    '''\n",
    "    if hflip or vflip:\n",
    "        if hflip and vflip:\n",
    "            c = -1\n",
    "        else:\n",
    "            c = 0 if vflip else 1\n",
    "        image = cv2.flip(img, flipCode=c)\n",
    "    return image\n",
    "\n",
    "\n",
    "def decrease_brightness(img):\n",
    "    '''\n",
    "    Decrease brightness of image\n",
    "    :param img: ndarray, BGR image\n",
    "    :return: ndarray, BGR image\n",
    "    '''\n",
    "    bright = np.ones(img.shape, dtype=\"uint8\") * -50\n",
    "    bright_image = cv2.add(img,bright)\n",
    "    return bright_image\n",
    "\n",
    "\n",
    "def add_noise_image(img):\n",
    "    '''\n",
    "    Add random noise to image\n",
    "    :param img: ndarray, BGR image\n",
    "    :return: ndarray, BGR image\n",
    "    '''\n",
    "    img = img_as_float(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    noise = random_noise(img, mode='s&p', amount=0.011)\n",
    "    noise = cv2.cvtColor(img_as_ubyte(noise), cv2.COLOR_RGB2BGR)\n",
    "    return noise\n",
    "\n",
    "\n",
    "def rotate_image(img, angle):\n",
    "    '''\n",
    "    Rotate image\n",
    "    :param img: ndarray, BGR image\n",
    "    :param angle: angle of rotation as int\n",
    "    :return: ndarray, BGR image\n",
    "    '''\n",
    "    angle = int(random.uniform(-angle, angle))\n",
    "    h, w = img.shape[:2]\n",
    "    matrix = cv2.getRotationMatrix2D((int(w/2), int(h/2)), angle, 1)\n",
    "    img = cv2.warpAffine(img, matrix, (w, h))\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_dataset(dataset_path, new_set_path, csv_path,\n",
    "                    reduced_csv_path, sample_number=50, validation=False):\n",
    "    '''\n",
    "    Prepare dataset and split it into training and validation dataset\n",
    "    :param dataset_path: Path to the original dataset with all images\n",
    "    :param new_set_path: Path where to save  images\n",
    "    :param csv_path: Path to the original  csv\n",
    "    :param reduced_csv_path: Path to the new  csv containing the pictures\n",
    "    :param sample_number: Number of samples per class for training dataset , maximum 1000\n",
    "    :param validation: Bool if dataset is validation set\n",
    "    :return:\n",
    "    '''\n",
    "    try:\n",
    "        new_dataset_dict = []\n",
    "        dataset_classes_dict = {}\n",
    "\n",
    "        dataset_path = dataset_path\n",
    "        new_set_path = new_set_path\n",
    "        df_dataset = pd.read_csv(csv_path)\n",
    "        classes_counter = {'MEL': 0, 'NV': 0, 'BCC': 0, 'AK': 0, 'BKL': 0, 'DF': 0, 'VASC': 0, 'SCC': 0}\n",
    "\n",
    "        # Shuffle dataset\n",
    "        if not validation:\n",
    "            df_dataset = df_dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        # Iterate over dataset\n",
    "        for i, image in df_dataset.iterrows():\n",
    "            dict1 = {}\n",
    "            if min(classes_counter.values()) > sample_number:\n",
    "                break\n",
    "            image_class = get_classification(image)\n",
    "            if image_class is not None and ((classes_counter[image_class] < sample_number) or validation):\n",
    "                img = cv2.imread(dataset_path + image['image'] + '.jpg')\n",
    "                img = cv2.resize(img, (600,600))\n",
    "                cv2.imwrite(new_set_path + image['image'] + '.jpg', img)\n",
    "                shutil.copy(dataset_path + image['image']+'.jpg', new_set_path)\n",
    "                dict1.update(image)\n",
    "                new_dataset_dict.append(dict1)\n",
    "                dataset_classes_dict[image['image']] = image_class\n",
    "                classes_counter[image_class] += 1\n",
    "\n",
    "\n",
    "        # Get distribution printed before augmentation\n",
    "        for index, value in classes_counter.items():\n",
    "            print('Dataset distribution:')\n",
    "            print('Class: ' + index)\n",
    "            print('Number of images: ' + str(value))\n",
    "        print('##########################################')\n",
    "\n",
    "        if not validation:\n",
    "            # Data augmentation\n",
    "            for index, value in classes_counter.items():\n",
    "                print('\\n Data augmentation for class ' + index)\n",
    "\n",
    "                if value >= sample_number:\n",
    "                    print(index + ' has ' + str(value) + ' images. Skipping augmenatation for this class')\n",
    "                    continue\n",
    "                else:\n",
    "                    for i, image in df_dataset.iterrows():\n",
    "                        if classes_counter[index] > sample_number:\n",
    "                            break\n",
    "                        image_class = get_classification(image)\n",
    "                        if image_class == index:\n",
    "                            print('Add augmented images for ' + image['image'])\n",
    "                            print('Number of samples for class: ' + index + '     ' + str(classes_counter[index]))\n",
    "                            img = cv2.imread(dataset_path + image['image']+'.jpg')\n",
    "                            img = cv2.resize(img, (600, 600))\n",
    "                            flip_h = flip_image(img,hflip=True)\n",
    "                            flip_v = flip_image(img, vflip=True)\n",
    "                            noise = add_noise_image(img)\n",
    "                            rotate = rotate_image(img, 90)\n",
    "                            rotate2 = rotate_image(img, 270)\n",
    "\n",
    "                            augmented_images = [flip_h, flip_v, rotate2, noise, rotate]\n",
    "\n",
    "                            for idx, aug_image in enumerate(augmented_images):\n",
    "                                dict1 = {}\n",
    "                                aug_image_name = f\"{image['image']}_{idx}\"\n",
    "                                cv2.imwrite(new_set_path + aug_image_name + \".jpg\", aug_image)\n",
    "                                dict1.update(image)\n",
    "                                dict1['image'] = aug_image_name\n",
    "                                new_dataset_dict.append(dict1)\n",
    "                                dataset_classes_dict[aug_image_name] = image_class\n",
    "                                classes_counter[index]+=1\n",
    "\n",
    "            print('############################################')\n",
    "            # Get distribution printed\n",
    "            for index, value in classes_counter.items():\n",
    "                print('Training set distribution:')\n",
    "                print('Class: ' + index)\n",
    "                print('Number of images: ' + str(value))\n",
    "\n",
    "        df_updated = pd.DataFrame(new_dataset_dict)\n",
    "        df_updated.to_csv(reduced_csv_path, index=False)\n",
    "\n",
    "    except OSError as e:\n",
    "        print(e)\n",
    "\n",
    "    print(\"Data structure created\")\n",
    "\n",
    "\n",
    "def read_csv_files(train_csv, val_csv):\n",
    "    '''\n",
    "    Read csv files for training and validation\n",
    "    :param train_csv: Path to train csv file\n",
    "    :param val_csv: Path to val csv file\n",
    "    :return: dict train_classes (key: image_name, value: class), dict val_classes (key: image_name, value: class)\n",
    "    '''\n",
    "    train_classes = {}\n",
    "    val_classes = {}\n",
    "    df_train = pd.read_csv(train_csv)\n",
    "    df_val = pd.read_csv(val_csv)\n",
    "\n",
    "    for i, image in df_train.iterrows():\n",
    "        image_class = get_classification(image)\n",
    "        if image_class is not None:\n",
    "            train_classes[image['image']] = image_class\n",
    "\n",
    "    for i, image in df_val.iterrows():\n",
    "        image_class = get_classification(image)\n",
    "        if image_class is not None:\n",
    "            val_classes[image['image']] = image_class\n",
    "\n",
    "    return train_classes, val_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3JqDDhUNPi-"
   },
   "source": [
    "**Preprocess**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "r5AXOmjLNSXG"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import exposure, morphology, filters, img_as_ubyte, img_as_float\n",
    "from skimage.color.adapt_rgb import adapt_rgb, each_channel\n",
    "\n",
    "\n",
    "def enlarge_image(img):\n",
    "    '''\n",
    "    Enlarge image with dark border areas\n",
    "    :param img: ndarray, BGR image\n",
    "    :return: ndarray, BGR image\n",
    "    '''\n",
    "    f = np.zeros((700, 700,3), np.uint8)\n",
    "    ax, ay = (700 - img.shape[1]) // 2, (700 - img.shape[0]) // 2\n",
    "    f[ay:img.shape[0] + ay, ax:ax + img.shape[1]] = img\n",
    "    return f\n",
    "\n",
    "\n",
    "def reduce_image(img):\n",
    "    '''\n",
    "    Resize image to size 600x600 and remove dark border areas\n",
    "    :param img: ndarray, BGR image\n",
    "    :return: ndarray, BGR image\n",
    "    '''\n",
    "    ax, ay = (img.shape[1]-600)//2, (img.shape[0] - 600) // 2\n",
    "    f = img[ay:600 + ay, ax:ax + 600]\n",
    "    return f\n",
    "\n",
    "\n",
    "def reduce_mask(img):\n",
    "    '''\n",
    "    Reuce mask size to 600x600\n",
    "    :param img: ndarray, binary image\n",
    "    :return: ndarray, binary image\n",
    "    '''\n",
    "    ax, ay = (img.shape[1]-600)//2, (img.shape[0] - 600) // 2\n",
    "    f = img[ay:600 + ay, ax:ax + 600]\n",
    "    return f\n",
    "\n",
    "\n",
    "def remove_black_border(gray_image):\n",
    "    '''\n",
    "    Remove black border areas\n",
    "    :param gray_image: ndarray, grayscale image\n",
    "    :return: ndarray, binary image\n",
    "    '''\n",
    "    _, mask = cv2.threshold(gray_image, 10, 255, cv2.THRESH_BINARY);\n",
    "    (contours, _) = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    c = max(contours, key=cv2.contourArea)\n",
    "    mask_a = np.zeros((700, 700), np.uint8)\n",
    "    cv2.drawContours(mask_a, [c], -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "    kernel = np.ones((15, 15), np.uint8)\n",
    "    eroded = cv2.erode(mask_a, kernel, iterations=3)\n",
    "    _, mask_a = cv2.threshold(eroded, 10, 255, cv2.THRESH_BINARY);\n",
    "    return mask_a\n",
    "\n",
    "\n",
    "@adapt_rgb(each_channel)\n",
    "def morph_closing_each(image, struct_element):\n",
    "    return morphology.closing(image, struct_element)\n",
    "\n",
    "\n",
    "@adapt_rgb(each_channel)\n",
    "def median_filter_each(image, struct_element):\n",
    "    return filters.median(image, struct_element)\n",
    "\n",
    "\n",
    "structuring_element = morphology.disk(7)\n",
    "\n",
    "\n",
    "def crop_center_rgb(img, cropx, cropy):\n",
    "    '''\n",
    "    Crop image from the center\n",
    "    :param img: ndarray, BGR image\n",
    "    :param cropx: width in int\n",
    "    :param cropy: height in int\n",
    "    :return: ndarray, BGR cropped image\n",
    "    '''\n",
    "    y,x,_ = img.shape\n",
    "    startx = x//2-(cropx//2)\n",
    "    starty = y//2-(cropy//2)\n",
    "    return img[starty:starty+cropy,startx:startx+cropx,:]\n",
    "\n",
    "\n",
    "def noise_removal(img):\n",
    "    '''\n",
    "    Remove noise in the image\n",
    "    :param img: ndarray, BGR image\n",
    "    :return: ndarray, BGR filtered image\n",
    "    '''\n",
    "    img = img_as_float(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    equalized_adapthist = exposure.equalize_adapthist(img)\n",
    "    img_morph_closing = morph_closing_each(equalized_adapthist, structuring_element)\n",
    "    img_filtered = median_filter_each(img_morph_closing, structuring_element)\n",
    "    img_filtered = cv2.cvtColor(img_as_ubyte(img_filtered), cv2.COLOR_RGB2BGR)\n",
    "    return img_filtered\n",
    "\n",
    "\n",
    "# Not used anymore\n",
    "# See https://www.kaggle.com/apacheco/shades-of-gray-color-constancy\n",
    "def shade_of_gray_cc(img, power=6, gamma=None):\n",
    "    \"\"\"\n",
    "    img (numpy array): the original image with format of (h, w, c)\n",
    "    power (int): the degree of norm, 6 is used in reference paper\n",
    "    gamma (float): the value of gamma correction, 2.2 is used in reference paper\n",
    "    \"\"\"\n",
    "    img_dtype = img.dtype\n",
    "\n",
    "    if gamma is not None:\n",
    "        img = img.astype('uint8')\n",
    "        look_up_table = np.ones((256, 1), dtype='uint8') * 0\n",
    "        for i in range(256):\n",
    "            look_up_table[i][0] = 255 * pow(i / 255, 1 / gamma)\n",
    "        img = cv2.LUT(img, look_up_table)\n",
    "\n",
    "    img = img.astype('float32')\n",
    "    img_power = np.power(img, power)\n",
    "    rgb_vec = np.power(np.mean(img_power, (0, 1)), 1 / power)\n",
    "    rgb_norm = np.sqrt(np.sum(np.power(rgb_vec, 2.0)))\n",
    "    rgb_vec = rgb_vec / rgb_norm\n",
    "    rgb_vec = 1 / (rgb_vec * np.sqrt(3))\n",
    "    img = np.multiply(img, rgb_vec)\n",
    "\n",
    "    # Andrew Anikin suggestion\n",
    "    img = np.clip(img, a_min=0, a_max=255)\n",
    "\n",
    "    return img.astype(img_dtype)\n",
    "\n",
    "\n",
    "def preprocess_image(img):\n",
    "    '''\n",
    "    Preprocess image\n",
    "    :param img: ndarray, BGR image\n",
    "    :return:  ndarray, BGR image\n",
    "    '''\n",
    "    img = noise_removal(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def crop_image(img):\n",
    "    '''\n",
    "    Remove dark border areas and crop image\n",
    "    :param img: ndarray, BGR image\n",
    "    :return: ndarray, BGR image\n",
    "    '''\n",
    "    img = cv2.resize(img, (600, 600))\n",
    "    inpaint_image = enlarge_image(img)\n",
    "\n",
    "    # Remove black border\n",
    "    gray = cv2.cvtColor(inpaint_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    mask = remove_black_border(gray)\n",
    "    #mean = cv2.mean(inpaint_image, mask)\n",
    "    mask = reduce_mask(mask)\n",
    "    inpaint_image = reduce_image(inpaint_image)\n",
    "    inpaint_image[mask == 0] = 0\n",
    "\n",
    "    coords = cv2.findNonZero(mask)\n",
    "    x, y, w, h = cv2.boundingRect(coords)\n",
    "    inpaint_image = inpaint_image[y:y + h, x:x + w]\n",
    "    inpaint_image = cv2.resize(inpaint_image, (600, 600))\n",
    "    # inpaint_image = shade_of_gray_cc(inpaint_image)\n",
    "\n",
    "    # Crop from the center the image if the borders are black\n",
    "    gray_img = cv2.cvtColor(inpaint_image, cv2.COLOR_BGR2GRAY)\n",
    "    if gray_img[0][0] < 10 and gray_img[0][-1] < 10 and gray_img[-1][0] < 10 and gray_img[-1][-1] < 10:\n",
    "        inpaint_image = cv2.resize(crop_center_rgb(inpaint_image, 400, 400), (600,600))\n",
    "    return inpaint_image\n",
    "\n",
    "\n",
    "def preprocess_dataset(dataset_path, dataset_csv_path, preprocessed_dataset_path):\n",
    "    '''\n",
    "    Preprocess training and validation dataset\n",
    "    :param dataset_path: Path to dataset\n",
    "    :param dataset_csv_path: Path to training csv file\n",
    "    :param val_csv_path: Path to validation csv file\n",
    "    :param preprocessed_dataset_path: Path where to save preprocessed  images\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    df_train = pd.read_csv(dataset_csv_path)\n",
    "\n",
    "    print('Start of preprocessing step of dataset ')\n",
    "    for i, image in df_train.iterrows():\n",
    "        img = cv2.imread(dataset_path + image['image']+'.jpg', cv2.IMREAD_COLOR)\n",
    "        img = preprocess_image(img)\n",
    "        cv2.imwrite(preprocessed_dataset_path + image['image']+'.jpg', img)\n",
    "        print(str(i) + ': Preprocessed image ' + image['image'])\n",
    "    print('Finished preprocess step of dataset')\n",
    "    print('preprocessed images saved in ' + preprocessed_dataset_path)\n",
    "    print('Finished script')\n",
    "\n",
    "\n",
    "def crop_dataset(dataset_path, dataset_csv_path):\n",
    "    '''\n",
    "    Crop training and validation dataset\n",
    "    :param dataset_path: Path to training dataset\n",
    "    :param dataset_csv_path: Path to training csv file\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    df_dataset = pd.read_csv(dataset_csv_path)\n",
    "\n",
    "    print('Start of dataset cropping step')\n",
    "    for i, image in df_dataset.iterrows():\n",
    "        img = cv2.imread(dataset_path + image['image']+'.jpg', cv2.IMREAD_COLOR)\n",
    "        img = crop_image(img)\n",
    "        cv2.imwrite(dataset_path + image['image']+'.jpg', img)\n",
    "        print(str(i) + ': Cropped image ' + image['image'])\n",
    "    print('Finished cropping step of dataset')\n",
    "    print('cropped  images saved in ' + dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iprgv1fBNVyt"
   },
   "source": [
    "**Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "D81lxpT2NYzg"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(true_labels, predicted_labels, class_labels):\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title('Confusion matrix')\n",
    "    sns.heatmap(conf_matrix.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "                xticklabels=sorted(class_labels), yticklabels=sorted(class_labels))\n",
    "    plt.xlabel('true label')\n",
    "    plt.ylabel('predicted label')\n",
    "    plt.draw()\n",
    "    plt.tight_layout()\n",
    "    plt.show();\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_hist(hist):\n",
    "    plt.plot(hist.history[\"accuracy\"])\n",
    "    plt.plot(hist.history[\"val_accuracy\"])\n",
    "    plt.title(\"model accuracy\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5srZwNMGNdkm"
   },
   "source": [
    "**Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "RNq-vHAONb2b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, \\\n",
    "                            recall_score, accuracy_score, classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6TBEnb5Nfjf"
   },
   "outputs": [],
   "source": [
    "# Set paths\n",
    "train_set_path = \"/content/drive/MyDrive/uni/pastukai/data/images/training_set/\"\n",
    "val_set_path = \"/content/drive/MyDrive/uni/pastukai/data/images/val_set/\"\n",
    "\n",
    "dataset_path = '/content/drive/MyDrive/uni/pastukai/temp/dataset/'\n",
    "train_csv = '/content/drive/MyDrive/uni/pastukai/data/groundtruth_train.csv'\n",
    "train_reduced_csv = '/content/drive/MyDrive/uni/pastukai/data/reduced_groundtruth_train.csv'\n",
    "val_csv = '/content/drive/MyDrive/uni/pastukai/data/groundtruth_val.csv'\n",
    "val_reduced_csv = '/content/drive/MyDrive/uni/pastukai/data/reduced_groundtruth_val.csv'\n",
    "\n",
    "pastukai_path = \"/content/drive/MyDrive/uni/pastukai/\"\n",
    "\n",
    "# Preprocess data\n",
    "do_preprocess = True\n",
    "sample_number=400\n",
    "\n",
    "class_labels = ['MEL','NV','BCC','AK','BKL','DF','VASC','SCC']\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(train_set_path, exist_ok=True)\n",
    "os.makedirs(val_set_path, exist_ok=True)\n",
    "\n",
    "# Create directory for each class\n",
    "#for item in class_labels:\n",
    "#  os.makedirs(train_set_path + item)\n",
    "\n",
    "NUM_CLASSES = 8\n",
    "IMG_SIZE = 160\n",
    "dropout_rate = 0.4\n",
    "batch_size = 20\n",
    "epochs = 50\n",
    "print('Build directory structure')\n",
    "\n",
    "!ls  '/content/drive/MyDrive/uni/pastukai/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5R2knBGDNi1O"
   },
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "prepare_dataset(dataset_path,train_set_path, train_csv, train_reduced_csv, sample_number, validation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fJoIz4QVNlo_"
   },
   "outputs": [],
   "source": [
    "# Prepare validation data\n",
    "prepare_dataset(dataset_path,val_set_path, \n",
    "                        val_csv, val_reduced_csv, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QPYA-AC9N4gu"
   },
   "outputs": [],
   "source": [
    "# Skip this step if you intend to use the last dataset split\n",
    "# Remove black border from training  images \n",
    "crop_dataset(train_set_path, train_reduced_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFztIqutN5Iu"
   },
   "outputs": [],
   "source": [
    "# Skip this step if you intend to use the last dataset split\n",
    "# Remove black border from validation  images \n",
    "crop_dataset(val_set_path, val_reduced_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hd3Hfx9iN8AF"
   },
   "outputs": [],
   "source": [
    "# Preprocess data and save preprocessed training images\n",
    "if do_preprocess:\n",
    "    preprocess_dataset(train_set_path, train_reduced_csv, preprocessed_train_set_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3DbBo93iN8v4"
   },
   "outputs": [],
   "source": [
    "# Preprocess data and save preprocessed validation images\n",
    "if do_preprocess:\n",
    "    preprocess_dataset(val_set_path, val_reduced_csv, preprocessed_val_set_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2DKUk9fFN84w"
   },
   "outputs": [],
   "source": [
    "# Read dataframes\n",
    "train_df, val_df = read_csv_files(train_reduced_csv, val_reduced_csv)\n",
    "\n",
    "new_train = {}\n",
    "new_val = {}\n",
    "imageNames = []\n",
    "\n",
    "for key,value in train_df.items():\n",
    "  new_train[key+'.jpg'] = value\n",
    "\n",
    "for key,value in val_df.items():\n",
    "  new_val[key+'.jpg'] = value\n",
    "  imageNames.append(key)\n",
    "\n",
    "train_df = new_train\n",
    "val_df = new_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Hm4n-7D2N890"
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(list(train_df.items()), columns=['image_name','class'])\n",
    "val_df = pd.DataFrame(list(val_df.items()), columns=['image_name','class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "aGfrC1xSN9Ba"
   },
   "outputs": [],
   "source": [
    "# Models\n",
    "\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from keras import optimizers\n",
    "from keras.applications import VGG16\n",
    "from keras.applications import MobileNet, MobileNetV2, DenseNet121, InceptionV3, EfficientNetB5\n",
    "from keras.layers import Dense,GlobalAveragePooling2D,Flatten,Dropout,BatchNormalization,Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D,Input\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "def build_model_effnet(num_classes):\n",
    "  input_shape = (IMG_SIZE,IMG_SIZE,3)\n",
    "  conv_base = EfficientNetB5(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "  model = models.Sequential()\n",
    "  model.add(conv_base)\n",
    "  model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
    "  if dropout_rate > 0:\n",
    "      model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
    "  model.add(layers.Dense(num_classes, activation='softmax', name=\"fc_out\"))\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=0.1),\n",
    "              metrics=['acc'])\n",
    "  model.summary()\n",
    "  return model\n",
    "\n",
    "def build_model_mobilenet(num_classes):\n",
    "  base_model=MobileNet(weights='imagenet',include_top=False,input_shape=(IMG_SIZE, IMG_SIZE, 3)) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "\n",
    "  x=base_model.output\n",
    "  x=GlobalAveragePooling2D()(x)\n",
    "  x=Dropout(0.4)(x)\n",
    "\n",
    "  x=Dense(300,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better result\n",
    "  x=Dropout(0.4)(x)\n",
    "  x=BatchNormalization()(x)\n",
    "  x=Dense(100,activation='relu')(x) #dense layer 2\n",
    "  x=Dropout(0.4)(x)\n",
    "\n",
    "  x=Dense(50,activation='relu')(x) #dense layer 3\n",
    "  preds=Dense(num_classes,activation='softmax')(x) #final layer with softmax activation\n",
    "\n",
    "  model=Model(inputs=base_model.input,outputs=preds)\n",
    "  print(len(model.layers[:]))\n",
    "  for layer in model.layers[:85]:\n",
    "    layer.trainable=False\n",
    "  for layer in model.layers[85:]:\n",
    "    layer.trainable=True\n",
    "  model.summary()\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=0.1),\n",
    "              metrics=['acc'])\n",
    "  return model\n",
    "\n",
    "\n",
    "def build_model_MobileNetV2(num_classes):\n",
    "  base_model=MobileNetV2(weights='imagenet',include_top=False,input_shape=(IMG_SIZE, IMG_SIZE, 3)) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "\n",
    "  x=base_model.output\n",
    "  x=GlobalAveragePooling2D()(x)\n",
    "  x=Dropout(0.2)(x)\n",
    "\n",
    "  preds=Dense(num_classes,activation='softmax')(x) #final layer with softmax activation\n",
    "\n",
    "  model=Model(inputs=base_model.input,outputs=preds)\n",
    "  print(len(model.layers[:]))\n",
    "  for layer in model.layers[:85]:\n",
    "    layer.trainable=False\n",
    "  for layer in model.layers[85:]:\n",
    "    layer.trainable=True\n",
    "  model.summary()\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=0.1),\n",
    "              metrics=['acc'])\n",
    "  return model\n",
    "\n",
    "\n",
    "def build_model_InceptionV3(num_classes):\n",
    "  base_model=InceptionV3(weights='imagenet',include_top=False,input_shape=(IMG_SIZE, IMG_SIZE, 3)) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "\n",
    "  x=base_model.output\n",
    "  x=GlobalAveragePooling2D()(x)\n",
    "  x=Dropout(0.4)(x)\n",
    "\n",
    "  x=Dense(300,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better result\n",
    "  x=Dropout(0.4)(x)\n",
    "  x=BatchNormalization()(x)\n",
    "  x=Dense(100,activation='relu')(x) #dense layer 2\n",
    "  x=Dropout(0.4)(x)\n",
    "\n",
    "  x=Dense(50,activation='relu')(x) #dense layer 3\n",
    "  preds=Dense(num_classes,activation='softmax')(x) #final layer with softmax activation\n",
    "\n",
    "  model=Model(inputs=base_model.input,outputs=preds)\n",
    "  print(len(model.layers[:]))\n",
    "  for layer in model.layers[:85]:\n",
    "    layer.trainable=False\n",
    "  for layer in model.layers[85:]:\n",
    "    layer.trainable=True\n",
    "  model.summary()\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=0.1),\n",
    "              metrics=['acc'])\n",
    "  return model\n",
    "\n",
    "\n",
    "def build_model_DenseNet121(num_classes):\n",
    "  base_model=DenseNet121(weights='imagenet',include_top=False,input_shape=(IMG_SIZE, IMG_SIZE, 3)) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "\n",
    "  x=base_model.output\n",
    "  x=GlobalAveragePooling2D()(x)\n",
    "  x=Dropout(0.4)(x)\n",
    "\n",
    "  x=Dense(300,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better result\n",
    "  x=Dropout(0.4)(x)\n",
    "  x=BatchNormalization()(x)\n",
    "  x=Dense(100,activation='relu')(x) #dense layer 2\n",
    "  x=Dropout(0.4)(x)\n",
    "\n",
    "  x=Dense(50,activation='relu')(x) #dense layer 3\n",
    "  preds=Dense(num_classes,activation='softmax')(x) #final layer with softmax activation\n",
    "\n",
    "  model=Model(inputs=base_model.input,outputs=preds)\n",
    "  print(len(model.layers[:]))\n",
    "  for layer in model.layers[:85]:\n",
    "    layer.trainable=False\n",
    "  for layer in model.layers[85:]:\n",
    "    layer.trainable=True\n",
    "  model.summary()\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=0.1),\n",
    "              metrics=['acc'])\n",
    "  return model\n",
    "\n",
    "\n",
    "def own_model(num_classes):\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(50, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "\n",
    "  # convolutional layer\n",
    "  model.add(Conv2D(75, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "  model.add(Dropout(0.25))\n",
    "\n",
    "  model.add(Conv2D(125, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "  model.add(Dropout(0.25))\n",
    "\n",
    "  model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "  model.add(Dense(64))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(num_classes))\n",
    "  model.add(Activation('softmax'))\n",
    "\n",
    "  model.compile(loss='binary_crossentropy',\n",
    "                optimizer='rmsprop',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  #preds=Dense(num_classes,activation='softmax')(model) #final layer with softmax activation\n",
    "  model.summary()\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KNdDILASN9FU"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_iterator = datagen.flow_from_dataframe(train_df,\n",
    "                                            directory=train_set_path,\n",
    "                                            x_col='image_name',\n",
    "                                            y_col='class',\n",
    "                                            target_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                            batch_size=batch_size,\n",
    "                                            color_mode='rgb',\n",
    "                                            class_mode='categorical')\n",
    "\n",
    "val_iterator = datagen.flow_from_dataframe(val_df,\n",
    "                                            directory=val_set_path,\n",
    "                                            x_col='image_name',\n",
    "                                            y_col='class',\n",
    "                                            target_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                            batch_size=batch_size,\n",
    "                                            color_mode='rgb',\n",
    "                                            class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MO4BG3D2OMJN"
   },
   "outputs": [],
   "source": [
    "model = own_model(num_classes=NUM_CLASSES)\n",
    "history = model.fit(train_iterator,\n",
    "                    steps_per_epoch= train_iterator.samples // batch_size,\n",
    "                    epochs=160,\n",
    "                    validation_data=val_iterator,\n",
    "                    validation_steps= val_iterator.samples // batch_size,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hCZ0JmKtONym"
   },
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_x = range(len(acc))\n",
    "\n",
    "plt.plot(epochs_x, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs_x, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs_x, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs_x, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sb3mnm33OP1r"
   },
   "outputs": [],
   "source": [
    "model.save(\"/content/drive/MyDrive/uni/pastukai/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4gc0h4AA1v1"
   },
   "source": [
    "**Create CSV file for validation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "UutaAd3uA1SE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "    \n",
    "def create_results_file_csv(results_path, csv_name, images, predictions, max_predictions):\n",
    "    '''\n",
    "    :param results_path: Path to the results directory\n",
    "    :param csv_name: Name of the csv file\n",
    "    :param images: array of image names\n",
    "    :param predictions: Array of predicted class\n",
    "    :param max_predictions: Array with probability of the predictions\n",
    "    :return:\n",
    "    '''\n",
    "    # check length of both files if they are equal\n",
    "    if len(images) != len(predictions) or len(predictions) != len(max_predictions):\n",
    "        print(\"!!!!! Length is not the same of the image array and prediction array !!!!!    image lenght = \", len(images) , \" prediction length = \", len(predictions), \" max prediction length = \", len(max_predictions))\n",
    "        \n",
    "    # save imagesnames and predictions into csv file\n",
    "    with open(results_path + csv_name + '.csv','w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        # {'AK': 0, 'BCC': 1, 'BKL': 2, 'DF': 3, 'MEL': 4, 'NV': 5, 'SCC': 6, 'VASC': 7}\n",
    "        # {'AK': 0, 'BCC': 1, 'BKL': 2, 'DF': 3, 'MEL': 4, 'NV': 5, 'SCC': 6, 'VASC': 7}  \n",
    "        writer.writerow(['image', 'AK', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'SCC', 'VASC', 'UNK'])\n",
    "        print('hier:', predictions)\n",
    "        for i in range(len(images)):\n",
    "            if max_predictions[i] < 0.25:\n",
    "                writer.writerow([images[i],0,0,0,0,0,0,0,0,1])\n",
    "            else:\n",
    "                if predictions[i] == 0:\n",
    "                    writer.writerow([images[i],1,0,0,0,0,0,0,0,0])\n",
    "                elif predictions[i] == 1:\n",
    "                    writer.writerow([images[i],0,1,0,0,0,0,0,0,0])\n",
    "                elif predictions[i] == 2:\n",
    "                    writer.writerow([images[i],0,0,1,0,0,0,0,0,0])\n",
    "                elif predictions[i] == 3:\n",
    "                    writer.writerow([images[i],0,0,0,1,0,0,0,0,0])            \n",
    "                elif predictions[i] == 4:\n",
    "                    writer.writerow([images[i],0,0,0,0,1,0,0,0,0])\n",
    "                elif predictions[i] == 5:\n",
    "                    writer.writerow([images[i],0,0,0,0,0,1,0,0,0])\n",
    "                elif predictions[i] == 6:\n",
    "                    writer.writerow([images[i],0,0,0,0,0,0,1,0,0])\n",
    "                elif predictions[i] == 7:\n",
    "                    writer.writerow([images[i],0,0,0,0,0,0,0,1,0])\n",
    "                elif predictions[i] == 8:\n",
    "                    writer.writerow([images[i],0,0,0,0,0,0,0,0,1])\n",
    "                else:\n",
    "                    print('Error! this class is unknown! Number:', i, 'Prediction:', predictions[i], 'images:', images[i])\n",
    "\n",
    "    print(\"CSV file is created successfully.\")\n",
    "                 \n",
    "    \n",
    "    \n",
    "def getImageTestingNames(testing_set_csv_path):\n",
    "    '''\n",
    "    Get all testing images name\n",
    "    :param testing_set_csv_path:\n",
    "    :return: Array of image names\n",
    "    '''\n",
    "    df_testing = pd.read_csv(testing_set_csv_path)\n",
    "    image_names = []\n",
    "    \n",
    "    for i, image in df_testing.iterrows():\n",
    "        image_names.append(image['image'])\n",
    "    \n",
    "    return image_names\n",
    "\n",
    "\n",
    "\n",
    "def getMaxPredictions(predicted_testing_prob):\n",
    "    '''\n",
    "    Get from the svm output the maximum probability for each image\n",
    "    :param predicted_testing_prob: Probabilities for each class of every image\n",
    "    :return: Array of max probabilities\n",
    "    '''\n",
    "    max_prediction = []\n",
    "    for item in predicted_testing_prob:\n",
    "        max_prediction.append(max(item))\n",
    "    return max_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iRNtB02RBDRO"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "\n",
    "testing_iterator = datagen.flow_from_dataframe(dataframe=val_df,\n",
    "                                                directory=val_set_path,\n",
    "                                                x_col=\"image_name\",\n",
    "                                                y_col=None,\n",
    "                                                batch_size=batch_size,\n",
    "                                                seed=42,\n",
    "                                                shuffle=False,\n",
    "                                                class_mode=None,\n",
    "                                                target_size=(IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "val_iterator.reset()\n",
    "pred=model.predict_generator(val_iterator,\n",
    "                            verbose=1)\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "\n",
    "create_results_file_csv(pastukai_path,'prediction_val', imageNames, predicted_class_indices, getMaxPredictions(pred))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
