{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import preprocess as pp\n",
    "from scripts import segmentation as seg\n",
    "from scripts import feature_extraction_segmentation as fex\n",
    "from scripts import split_data\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, \\\n",
    "                            recall_score, accuracy_score, classification_report\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# K nearest neighbor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(true_labels, predicted_labels, class_labels):\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title('Confusion matrix')\n",
    "    sns.heatmap(conf_matrix.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "                xticklabels=sorted(class_labels), yticklabels=sorted(class_labels))\n",
    "    plt.xlabel('true label')\n",
    "    plt.ylabel('predicted label')\n",
    "    plt.draw()\n",
    "    plt.tight_layout()\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "cwd_path = os.getcwd()\n",
    "train_set_path = cwd_path + \"/data/images/training_set/\"\n",
    "val_set_path = cwd_path + \"/data/images/val_set/\"\n",
    "preprocessed_train_set_path = cwd_path + \"/data/images/preprocessed_train/\"\n",
    "preprocessed_val_set_path = cwd_path + \"/data/images/preprocessed_val/\"\n",
    "\n",
    "dataset_path = cwd_path + '/temp/dataset/'\n",
    "train_csv = cwd_path + '/data/groundtruth_train.csv'\n",
    "train_reduced_csv = cwd_path + '/data/reduced_groundtruth_train.csv'\n",
    "val_csv = cwd_path + '/data/groundtruth_val.csv'\n",
    "val_reduced_csv = cwd_path + '/data/reduced_groundtruth_val.csv'\n",
    "\n",
    "# Preprocess data\n",
    "do_preprocess = True\n",
    "sample_number=100\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(train_set_path, exist_ok=True)\n",
    "os.makedirs(val_set_path, exist_ok=True)\n",
    "os.makedirs(preprocessed_train_set_path, exist_ok=True)\n",
    "os.makedirs(preprocessed_val_set_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip this step if you intend to use the last dataset split\n",
    "# Split data\n",
    "split_data.prepare_dataset(dataset_path,train_set_path, val_set_path, train_csv,\n",
    "                           val_csv, train_reduced_csv, val_reduced_csv, sample_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip this step if you intend to use the last dataset split\n",
    "# Remove black border from training and validation images \n",
    "pp.crop_dataset(train_set_path, val_set_path, train_reduced_csv, val_reduced_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get output classes from training and validation data. You can not skip this step.\n",
    "train_classes, val_classes = split_data.read_csv_files(train_reduced_csv, val_reduced_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip this step if you intend to use the last dataset split\n",
    "# Preprocess data and save preprocessed images\n",
    "if do_preprocess:\n",
    "    pp.preprocess_dataset(train_set_path, val_set_path, train_reduced_csv, val_reduced_csv,\n",
    "                         preprocessed_train_set_path, preprocessed_val_set_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation\n",
    "tmp_segmented_lesion_train_set, tmp_segmented_lesion_val_set = seg.get_lesion_region(train_reduced_csv,val_reduced_csv,\n",
    "                  preprocessed_train_set_path, preprocessed_val_set_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove entries which are None\n",
    "segmented_lesion_train_set = {}\n",
    "for key,value in tmp_segmented_lesion_train_set.items():\n",
    "    if value is not None:\n",
    "        segmented_lesion_train_set[key] = value\n",
    "        \n",
    "# Remove entries which are None\n",
    "segmented_lesion_val_set = {}\n",
    "for key,value in tmp_segmented_lesion_val_set.items():\n",
    "    if value is not None:\n",
    "        segmented_lesion_val_set[key] = value\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction\n",
    "features_train, features_test = fex.features_extraction(segmented_lesion_train_set, segmented_lesion_val_set, \n",
    "                train_set_path, val_set_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Nans\n",
    "tmp_features_train = pd.DataFrame.from_dict(features_train)\n",
    "tmp_features_train = tmp_features_train.fillna(0)\n",
    "features_train_input = tmp_features_train.to_dict('list')\n",
    "\n",
    "tmp_features_val = pd.DataFrame.from_dict(features_test)\n",
    "tmp_features_val = tmp_features_val.fillna(0)\n",
    "features_test_input = tmp_features_val.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation data\n",
    "train_names = list(features_train_input.keys())\n",
    "test_names = list(features_test_input.keys())\n",
    "\n",
    "X_test = list(features_test_input.values())\n",
    "X_train = list(features_train_input.values())\n",
    "\n",
    "# normalizing features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "for img_name in train_names:\n",
    "    y_train.append(train_classes[img_name])\n",
    "\n",
    "for img_name in test_names:\n",
    "    y_test.append(val_classes[img_name])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training the SVM classifier...\")\n",
    "\n",
    "param_grid = {'C': [1, 1e1, 1e2, 1e3, 5e3, 1e4],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],\n",
    "              'class_weight': [None, 'balanced']}\n",
    "clf = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, iid=False)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Best estimator found by Grid Search:\")\n",
    "print(clf.best_estimator_)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_labels = ['MEL','NV','BCC','AK','BKL','DF','VASC','SCC']\n",
    "print('*** TEST SET PERFORMANCE EVALUATION - Segmentation + Feature Extraction + SVM ***')\n",
    "# compute and plot performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "val_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "val_recall = recall_score(y_test, y_pred, average='weighted')\n",
    "val_precision = precision_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print('Accuracy: {:.3f}'.format(accuracy))\n",
    "print('F1-score: {:.3f}'.format(val_f1))\n",
    "print('Recall: {:.3f}'.format(val_recall))\n",
    "print('Precision: {:.3f}'.format(val_precision))\n",
    "\n",
    "print('\\nClassification report:')\n",
    "print(classification_report(y_test, y_pred, target_names=class_labels))\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred, class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#KNN K = 15 -> \"Best\" accuracy\n",
    "\n",
    "param_grid = {'C': [1, 1e1, 1e2, 1e3, 5e3, 1e4],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],\n",
    "              'class_weight': [None, 'balanced']}\n",
    "clf2 = KNeighborsClassifier(15)\n",
    "clf2 = clf2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\")\n",
    "predicted = clf2.predict(X_test)\n",
    "print(1 - (sum(1 for i in (predicted == y_test) if i==False)/len(predicted)))\n",
    "\n",
    "predicted_testing = clf2.predict(X_testing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN K = 15, distance \n",
    "\n",
    "param_grid = {'C': [1, 1e1, 1e2, 1e3, 5e3, 1e4],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],\n",
    "              'class_weight': [None, 'balanced']}\n",
    "clf2 = KNeighborsClassifier(15, weights='distance')\n",
    "clf2 = clf2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\")\n",
    "predicted = clf2.predict(X_test)\n",
    "print(1 - (sum(1 for i in (predicted == y_test) if i==False)/len(predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN K = 50, distance\n",
    "\n",
    "param_grid = {'C': [1, 1e1, 1e2, 1e3, 5e3, 1e4],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],\n",
    "              'class_weight': [None, 'balanced']}\n",
    "clf2 = KNeighborsClassifier(50, weights='distance')\n",
    "clf2 = clf2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\")\n",
    "predicted = clf2.predict(X_test)\n",
    "print(1 - (sum(1 for i in (predicted == y_test) if i==False)/len(predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN K = 15, uniform \n",
    "\n",
    "param_grid = {'C': [1, 1e1, 1e2, 1e3, 5e3, 1e4],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],\n",
    "              'class_weight': [None, 'balanced']}\n",
    "clf2 = KNeighborsClassifier(15, weights='uniform')\n",
    "clf2 = clf2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\")\n",
    "predicted = clf2.predict(X_test)\n",
    "print(1 - (sum(1 for i in (predicted == y_test) if i==False)/len(predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN K = 50, uniform \n",
    "\n",
    "param_grid = {'C': [1, 1e1, 1e2, 1e3, 5e3, 1e4],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],\n",
    "              'class_weight': [None, 'balanced']}\n",
    "clf2 = KNeighborsClassifier(50, weights='uniform')\n",
    "clf2 = clf2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\")\n",
    "predicted = clf2.predict(X_test)\n",
    "print(1 - (sum(1 for i in (predicted == y_test) if i==False)/len(predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree - Gini \n",
    "\n",
    "param_grid = {'C': [1, 1e1, 1e2, 1e3, 5e3, 1e4],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],\n",
    "              'class_weight': [None, 'balanced']}\n",
    "clf2 = DecisionTreeClassifier(criterion='gini')\n",
    "clf2 = clf2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\")\n",
    "predicted = clf2.predict(X_test)\n",
    "print(1 - (sum(1 for i in (predicted == y_test) if i==False)/len(predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree - Entropy \n",
    "\n",
    "param_grid = {'C': [1, 1e1, 1e2, 1e3, 5e3, 1e4],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],\n",
    "              'class_weight': [None, 'balanced']}\n",
    "clf2 = DecisionTreeClassifier(criterion='gini')\n",
    "clf2 = clf2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\")\n",
    "predicted = clf2.predict(X_test)\n",
    "print(1 - (sum(1 for i in (predicted == y_test) if i==False)/len(predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
