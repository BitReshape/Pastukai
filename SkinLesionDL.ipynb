{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "kxk2C37_kJs-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google.colab\n",
      "  Using cached https://files.pythonhosted.org/packages/70/9f/d3ec1275a089ec017f9c91af22ecd1e2fe738254b944e7a1f9528fcfacd0/google-colab-1.0.0.tar.gz\n",
      "Collecting google-auth~=1.4.0 (from google.colab)\n",
      "  Using cached https://files.pythonhosted.org/packages/56/80/369a47c28ce7d9be6a6973338133d073864d8efbb62747e414c34a3a5f4f/google_auth-1.4.2-py2.py3-none-any.whl\n",
      "Collecting ipykernel~=4.6.0 (from google.colab)\n",
      "  Using cached https://files.pythonhosted.org/packages/18/c3/76775a650cae2e3d9c033b26153583e61282692d9a3af12a3022d8f0cefa/ipykernel-4.6.1-py3-none-any.whl\n",
      "Collecting ipython~=5.5.0 (from google.colab)\n",
      "  Using cached https://files.pythonhosted.org/packages/07/63/c987612bcf82c56eaacaf6bf01e31e53a244a0a3a0fb036ec5adc377e0fe/ipython-5.5.0-py3-none-any.whl\n",
      "Collecting notebook~=5.2.0 (from google.colab)\n",
      "  Using cached https://files.pythonhosted.org/packages/96/a2/d951ebb7855743f989287486ded73cd3f66915c3ecd9c5c5a0c7ca12377a/notebook-5.2.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six~=1.12.0 in /opt/anaconda3/lib/python3.7/site-packages (from google.colab) (1.12.0)\n",
      "Collecting pandas~=0.24.0 (from google.colab)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/43/fd867e3347559845c8f993059d410c50a1e18709f1c4d4b3b47323a06a37/pandas-0.24.2-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (15.9MB)\n",
      "\u001b[K     |████████████████████████████████| 15.9MB 966kB/s eta 0:00:01    |█████▉                          | 2.9MB 5.1MB/s eta 0:00:03     |██████▋                         | 3.3MB 5.1MB/s eta 0:00:03     |████████                        | 4.0MB 5.1MB/s eta 0:00:03     |███████████▊                    | 5.8MB 5.1MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting portpicker~=1.2.0 (from google.colab)\n",
      "  Using cached https://files.pythonhosted.org/packages/49/2c/a75ef568273036aa61319a554164e6031e31708106ea6ca10e17265e1703/portpicker-1.2.0.tar.gz\n",
      "Collecting requests~=2.21.0 (from google.colab)\n",
      "  Using cached https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl\n",
      "Collecting tornado~=4.5.0 (from google.colab)\n",
      "  Using cached https://files.pythonhosted.org/packages/e3/7b/e29ab3d51c8df66922fea216e2bddfcb6430fb29620e5165b16a216e0d3c/tornado-4.5.3.tar.gz\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth~=1.4.0->google.colab)\n",
      "  Using cached https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl\n",
      "Collecting cachetools>=2.0.0 (from google-auth~=1.4.0->google.colab)\n",
      "  Using cached https://files.pythonhosted.org/packages/92/da/d3c94fc7c72ad9298072681ec3e8cea86949acc5c4cce4290ba21f7050a8/cachetools-4.2.0-py3-none-any.whl\n",
      "Collecting rsa>=3.1.4 (from google-auth~=1.4.0->google.colab)\n",
      "  Using cached https://files.pythonhosted.org/packages/bf/87/dc7a6ebf0afbc602548627fa48e9c1147fa187233bf71d4c51c76a2cfb27/rsa-4.7-py3-none-any.whl\n",
      "Requirement already satisfied: jupyter-client in /opt/anaconda3/lib/python3.7/site-packages (from ipykernel~=4.6.0->google.colab) (5.3.3)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in /opt/anaconda3/lib/python3.7/site-packages (from ipykernel~=4.6.0->google.colab) (4.3.3)\n",
      "Requirement already satisfied: pickleshare in /opt/anaconda3/lib/python3.7/site-packages (from ipython~=5.5.0->google.colab) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/anaconda3/lib/python3.7/site-packages (from ipython~=5.5.0->google.colab) (41.4.0)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /opt/anaconda3/lib/python3.7/site-packages (from ipython~=5.5.0->google.colab) (0.8.1)\n",
      "Collecting prompt-toolkit<2.0.0,>=1.0.4 (from ipython~=5.5.0->google.colab)\n",
      "  Using cached https://files.pythonhosted.org/packages/64/27/5fd61a451d086ad4aa806dc72fe1383d2bc0e74323668672287f616d5d51/prompt_toolkit-1.0.18-py3-none-any.whl\n",
      "Requirement already satisfied: appnope; sys_platform == \"darwin\" in /opt/anaconda3/lib/python3.7/site-packages (from ipython~=5.5.0->google.colab) (0.1.0)\n",
      "Requirement already satisfied: pygments in /opt/anaconda3/lib/python3.7/site-packages (from ipython~=5.5.0->google.colab) (2.4.2)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/anaconda3/lib/python3.7/site-packages (from ipython~=5.5.0->google.colab) (4.7.0)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/lib/python3.7/site-packages (from ipython~=5.5.0->google.colab) (4.4.0)\n",
      "Requirement already satisfied: nbformat in /opt/anaconda3/lib/python3.7/site-packages (from notebook~=5.2.0->google.colab) (4.4.0)\n",
      "Requirement already satisfied: nbconvert in /opt/anaconda3/lib/python3.7/site-packages (from notebook~=5.2.0->google.colab) (5.6.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/anaconda3/lib/python3.7/site-packages (from notebook~=5.2.0->google.colab) (0.2.0)\n",
      "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /opt/anaconda3/lib/python3.7/site-packages (from notebook~=5.2.0->google.colab) (0.8.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.7/site-packages (from notebook~=5.2.0->google.colab) (2.10.3)\n",
      "Requirement already satisfied: jupyter-core in /opt/anaconda3/lib/python3.7/site-packages (from notebook~=5.2.0->google.colab) (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/anaconda3/lib/python3.7/site-packages (from pandas~=0.24.0->google.colab) (1.17.2)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/anaconda3/lib/python3.7/site-packages (from pandas~=0.24.0->google.colab) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/anaconda3/lib/python3.7/site-packages (from pandas~=0.24.0->google.colab) (2.8.0)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/anaconda3/lib/python3.7/site-packages (from requests~=2.21.0->google.colab) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/anaconda3/lib/python3.7/site-packages (from requests~=2.21.0->google.colab) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.7/site-packages (from requests~=2.21.0->google.colab) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from requests~=2.21.0->google.colab) (3.0.4)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth~=1.4.0->google.colab)\n",
      "  Using cached https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/anaconda3/lib/python3.7/site-packages (from jupyter-client->ipykernel~=4.6.0->google.colab) (18.1.0)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/lib/python3.7/site-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython~=5.5.0->google.colab) (0.1.7)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython~=5.5.0->google.colab) (0.6.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/anaconda3/lib/python3.7/site-packages (from nbformat->notebook~=5.2.0->google.colab) (3.0.2)\n",
      "Requirement already satisfied: defusedxml in /opt/anaconda3/lib/python3.7/site-packages (from nbconvert->notebook~=5.2.0->google.colab) (0.6.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/anaconda3/lib/python3.7/site-packages (from nbconvert->notebook~=5.2.0->google.colab) (0.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/anaconda3/lib/python3.7/site-packages (from nbconvert->notebook~=5.2.0->google.colab) (1.4.2)\n",
      "Requirement already satisfied: bleach in /opt/anaconda3/lib/python3.7/site-packages (from nbconvert->notebook~=5.2.0->google.colab) (3.1.0)\n",
      "Requirement already satisfied: testpath in /opt/anaconda3/lib/python3.7/site-packages (from nbconvert->notebook~=5.2.0->google.colab) (0.4.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/anaconda3/lib/python3.7/site-packages (from nbconvert->notebook~=5.2.0->google.colab) (0.8.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/anaconda3/lib/python3.7/site-packages (from jinja2->notebook~=5.2.0->google.colab) (1.1.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook~=5.2.0->google.colab) (19.2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/anaconda3/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook~=5.2.0->google.colab) (0.15.4)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/lib/python3.7/site-packages (from bleach->nbconvert->notebook~=5.2.0->google.colab) (0.5.1)\n",
      "Building wheels for collected packages: google.colab, portpicker, tornado\n",
      "  Building wheel for google.colab (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google.colab: filename=google_colab-1.0.0-py2.py3-none-any.whl size=102290 sha256=6cb5e3cc7a43027c22b622c8ccc8bd9b197552893e7ee81b7b150a70bbf67098\n",
      "  Stored in directory: /Users/vanessaklebe/Library/Caches/pip/wheels/38/0d/59/701e300a337b2a2e07b27fe74dbfff0bc56ac58f711566ee67\n",
      "  Building wheel for portpicker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for portpicker: filename=portpicker-1.2.0-cp37-none-any.whl size=13369 sha256=5e16bd38a738416ba6ddba7e48201a81d0eb01968aa0bec07228fc33151e8705\n",
      "  Stored in directory: /Users/vanessaklebe/Library/Caches/pip/wheels/4a/45/47/1e126be9d4605e71f00d6e6fb151611f2f4cb9770b050c7d2d\n",
      "  Building wheel for tornado (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tornado: filename=tornado-4.5.3-cp37-cp37m-macosx_10_9_x86_64.whl size=422296 sha256=d87a7d18c15fb0918673ce40fa1d7dbe0d7266a7a343080c4fb0eece40b892ce\n",
      "  Stored in directory: /Users/vanessaklebe/Library/Caches/pip/wheels/72/bf/f4/b68fa69596986881b397b18ff2b9af5f8181233aadcc9f76fd\n",
      "Successfully built google.colab portpicker tornado\n",
      "\u001b[31mERROR: spyder-kernels 0.5.2 has requirement ipykernel>=4.8.2, but you'll have ipykernel 4.6.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyter-console 6.0.0 has requirement prompt_toolkit<2.1.0,>=2.0.0, but you'll have prompt-toolkit 1.0.18 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: distributed 2.5.2 has requirement tornado>=5, but you'll have tornado 4.5.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: pyasn1, pyasn1-modules, cachetools, rsa, google-auth, tornado, prompt-toolkit, ipython, ipykernel, notebook, pandas, portpicker, requests, google.colab\n",
      "  Found existing installation: tornado 6.0.3\n",
      "    Uninstalling tornado-6.0.3:\n",
      "      Successfully uninstalled tornado-6.0.3\n",
      "  Found existing installation: prompt-toolkit 2.0.10\n",
      "    Uninstalling prompt-toolkit-2.0.10:\n",
      "      Successfully uninstalled prompt-toolkit-2.0.10\n",
      "  Found existing installation: ipython 7.8.0\n",
      "    Uninstalling ipython-7.8.0:\n",
      "      Successfully uninstalled ipython-7.8.0\n",
      "  Found existing installation: ipykernel 5.1.2\n",
      "    Uninstalling ipykernel-5.1.2:\n",
      "      Successfully uninstalled ipykernel-5.1.2\n",
      "  Found existing installation: notebook 6.0.1\n",
      "    Uninstalling notebook-6.0.1:\n",
      "      Successfully uninstalled notebook-6.0.1\n",
      "  Found existing installation: pandas 0.25.1\n",
      "    Uninstalling pandas-0.25.1:\n",
      "      Successfully uninstalled pandas-0.25.1\n",
      "  Found existing installation: requests 2.22.0\n",
      "    Uninstalling requests-2.22.0:\n",
      "      Successfully uninstalled requests-2.22.0\n",
      "Successfully installed cachetools-4.2.0 google-auth-1.4.2 google.colab ipykernel-4.6.1 ipython-5.5.0 notebook-5.2.2 pandas-0.24.2 portpicker-1.2.0 prompt-toolkit-1.0.18 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.21.0 rsa-4.7 tornado-4.5.3\n"
     ]
    }
   ],
   "source": [
    "# Skin Lesion\n",
    "import sys\n",
    "!{sys.executable} -m pip install google.colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "hkG61jXJub99"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/utils/traitlets.py:5: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  warn(\"IPython.utils.traitlets has moved to a top-level traitlets package.\")\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'CLOUDSDK_CONFIG'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-91874b305a32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m   \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m   \u001b[0mhome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhome\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m   \u001b[0mroot_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_env\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0mhome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HOME'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   root_dir = _os.path.realpath(\n\u001b[0;32m---> 43\u001b[0;31m       _os.path.join(_os.environ['CLOUDSDK_CONFIG'], '../..'))\n\u001b[0m\u001b[1;32m     44\u001b[0m   \u001b[0minet_family\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'IPV4_ONLY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0mdev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/dev/fuse'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CLOUDSDK_CONFIG'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "YZdP_YyNcfxG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: /content/drive/MyDrive/uni/ism/pastukai/temp: Read-only file system\n",
      "mkdir: /content/drive/MyDrive/uni/ism/pastukai/data: Read-only file system\n",
      "[Errno 2] No such file or directory: '/content/drive/MyDrive/uni/ism/pastukai/temp'\n",
      "/Users/vanessaklebe/Documents/Tuhh_ComputerScienceStudium/Master/Semester_4/Intelligente_Medizinische_Systeme/Git/pastukai\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p \"/content/drive/MyDrive/uni/ism/pastukai/temp\"\n",
    "!mkdir -p \"/content/drive/MyDrive/uni/ism/pastukai/data\"\n",
    "%cd \"/content/drive/MyDrive/uni/ism/pastukai/temp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFcVfd8hg44o"
   },
   "source": [
    "Upload into \"/content/drive/MyDrive/uni/ism/pastukai/data\" both csv files (validation and training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Z-ES_GgYdaFi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Training Data ...\n",
      "Unpacking ISIC_2019_Training_Input.zip ...\n",
      "       0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 6: wget: command not found\n",
      "unzip:  cannot find or open ISIC_2019_Training_Input.zip, ISIC_2019_Training_Input.zip.zip or ISIC_2019_Training_Input.zip.ZIP.\n",
      "ls: /content/drive/MyDrive/uni/ism/pastukai/temp/dataset/: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "DATASET_DIR=\"/content/drive/MyDrive/uni/ism/pastukai/temp/dataset/\"\n",
    "\n",
    "if [ ! -f \"ISIC_2019_Training_Input.zip\" ]; then\n",
    "    echo \"Downloading Training Data ...\"\n",
    "    wget --show-progress --progress=bar:force https://isic-challenge-data.s3.amazonaws.com/2019/ISIC_2019_Training_Input.zip -O ISIC_2019_Training_Input.zip\n",
    "fi\n",
    "\n",
    "echo \"Unpacking ISIC_2019_Training_Input.zip ...\"\n",
    "unzip -q -j ISIC_2019_Training_Input.zip -d $DATASET_DIR\n",
    "\n",
    "# Number of files in dataset folder.\n",
    "ls $DATASET_DIR | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "qH9YJgGMeZl2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error when building the dataset\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "DATASET_DIR=\"/content/drive/MyDrive/uni/ism/pastukai/temp/dataset/\"\n",
    "\n",
    "if [ -d $DATASET_DIR ] && [ $(ls -1 $DATASET_DIR | wc -l) -eq 25333 ]; then\n",
    "    echo \"Successfully built the dataset\"\n",
    "else\n",
    "    echo \"Error when building the dataset\"\n",
    "fi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GbSveMhfhIKl"
   },
   "outputs": [],
   "source": [
    "% cd /content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6H7YKwJVBAi"
   },
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J3yRo0nMVI4n"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.util import random_noise\n",
    "from skimage import img_as_ubyte, img_as_float\n",
    "import random\n",
    "\n",
    "\n",
    "def get_classification(data_series):\n",
    "    '''\n",
    "\n",
    "    :param data_series: dataserie containing the one hotencoding\n",
    "    :return: classification as string\n",
    "    '''\n",
    "    classification = None\n",
    "    for index, value in data_series.items():\n",
    "        if value == 1.0:\n",
    "            classification = index\n",
    "    return classification\n",
    "\n",
    "\n",
    "# Augmentation functions\n",
    "def flip_image(img, vflip=False, hflip=False):\n",
    "    '''\n",
    "    Flip image vertically or horizontally\n",
    "    :param img: ndarray, BGR image\n",
    "    :param vflip: bool if vertically flip\n",
    "    :param hflip: bool if horizontally flip\n",
    "    :return: ndarray, BGR image\n",
    "    '''\n",
    "    if hflip or vflip:\n",
    "        if hflip and vflip:\n",
    "            c = -1\n",
    "        else:\n",
    "            c = 0 if vflip else 1\n",
    "        image = cv2.flip(img, flipCode=c)\n",
    "    return image\n",
    "\n",
    "\n",
    "def decrease_brightness(img):\n",
    "    '''\n",
    "    Decrease brightness of image\n",
    "    :param img: ndarray, BGR image\n",
    "    :return: ndarray, BGR image\n",
    "    '''\n",
    "    bright = np.ones(img.shape, dtype=\"uint8\") * -50\n",
    "    bright_image = cv2.add(img,bright)\n",
    "    return bright_image\n",
    "\n",
    "\n",
    "def add_noise_image(img):\n",
    "    '''\n",
    "    Add random noise to image\n",
    "    :param img: ndarray, BGR image\n",
    "    :return: ndarray, BGR image\n",
    "    '''\n",
    "    img = img_as_float(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    noise = random_noise(img, mode='s&p', amount=0.011)\n",
    "    noise = cv2.cvtColor(img_as_ubyte(noise), cv2.COLOR_RGB2BGR)\n",
    "    return noise\n",
    "\n",
    "\n",
    "def rotate_image(img, angle):\n",
    "    '''\n",
    "    Rotate image\n",
    "    :param img: ndarray, BGR image\n",
    "    :param angle: angle of rotation as int\n",
    "    :return: ndarray, BGR image\n",
    "    '''\n",
    "    angle = int(random.uniform(-angle, angle))\n",
    "    h, w = img.shape[:2]\n",
    "    matrix = cv2.getRotationMatrix2D((int(w/2), int(h/2)), angle, 1)\n",
    "    img = cv2.warpAffine(img, matrix, (w, h))\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_dataset(dataset_path, new_set_path, csv_path,\n",
    "                    reduced_csv_path, sample_number=50, validation=False):\n",
    "    '''\n",
    "    Prepare dataset and split it into training and validation dataset\n",
    "    :param dataset_path: Path to the original dataset with all images\n",
    "    :param new_set_path: Path where to save  images\n",
    "    :param csv_path: Path to the original  csv\n",
    "    :param reduced_csv_path: Path to the new  csv containing the pictures\n",
    "    :param sample_number: Number of samples per class for training dataset , maximum 1000\n",
    "    :param validation: Bool if dataset is validation set\n",
    "    :return:\n",
    "    '''\n",
    "    try:\n",
    "        new_dataset_dict = []\n",
    "        dataset_classes_dict = {}\n",
    "\n",
    "        dataset_path = dataset_path\n",
    "        new_set_path = new_set_path\n",
    "        df_dataset = pd.read_csv(csv_path)\n",
    "        classes_counter = {'MEL': 0, 'NV': 0, 'BCC': 0, 'AK': 0, 'BKL': 0, 'DF': 0, 'VASC': 0, 'SCC': 0}\n",
    "\n",
    "        # Shuffle dataset\n",
    "        if not validation:\n",
    "            df_dataset = df_dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        # Iterate over dataset\n",
    "        for i, image in df_dataset.iterrows():\n",
    "            dict1 = {}\n",
    "            if min(classes_counter.values()) > sample_number:\n",
    "                break\n",
    "            image_class = get_classification(image)\n",
    "            if image_class is not None and ((classes_counter[image_class] < sample_number) or validation):\n",
    "                img = cv2.imread(dataset_path + image['image'] + '.jpg')\n",
    "                img = cv2.resize(img, (600,600))\n",
    "                cv2.imwrite(new_set_path + image['image'] + '.jpg', img)\n",
    "                shutil.copy(dataset_path + image['image']+'.jpg', new_set_path)\n",
    "                dict1.update(image)\n",
    "                new_dataset_dict.append(dict1)\n",
    "                dataset_classes_dict[image['image']] = image_class\n",
    "                classes_counter[image_class] += 1\n",
    "\n",
    "\n",
    "        # Get distribution printed before augmentation\n",
    "        for index, value in classes_counter.items():\n",
    "            print('Dataset distribution:')\n",
    "            print('Class: ' + index)\n",
    "            print('Number of images: ' + str(value))\n",
    "        print('##########################################')\n",
    "\n",
    "        if not validation:\n",
    "            # Data augmentation\n",
    "            for index, value in classes_counter.items():\n",
    "                print('\\n Data augmentation for class ' + index)\n",
    "\n",
    "                if value >= sample_number:\n",
    "                    print(index + ' has ' + str(value) + ' images. Skipping augmenatation for this class')\n",
    "                    continue\n",
    "                else:\n",
    "                    for i, image in df_dataset.iterrows():\n",
    "                        if classes_counter[index] > sample_number:\n",
    "                            break\n",
    "                        image_class = get_classification(image)\n",
    "                        if image_class == index:\n",
    "                            print('Add augmented images for ' + image['image'])\n",
    "                            print('Number of samples for class: ' + index + '     ' + str(classes_counter[index]))\n",
    "                            img = cv2.imread(dataset_path + image['image']+'.jpg')\n",
    "                            img = cv2.resize(img, (600, 600))\n",
    "                            flip_h = flip_image(img,hflip=True)\n",
    "                            flip_v = flip_image(img, vflip=True)\n",
    "                            noise = add_noise_image(img)\n",
    "                            rotate = rotate_image(img, 90)\n",
    "                            rotate2 = rotate_image(img, 270)\n",
    "\n",
    "                            augmented_images = [flip_h, flip_v, rotate2, noise, rotate]\n",
    "\n",
    "                            for idx, aug_image in enumerate(augmented_images):\n",
    "                                dict1 = {}\n",
    "                                aug_image_name = f\"{image['image']}_{idx}\"\n",
    "                                cv2.imwrite(new_set_path + aug_image_name + \".jpg\", aug_image)\n",
    "                                dict1.update(image)\n",
    "                                dict1['image'] = aug_image_name\n",
    "                                new_dataset_dict.append(dict1)\n",
    "                                dataset_classes_dict[aug_image_name] = image_class\n",
    "                                classes_counter[index]+=1\n",
    "\n",
    "            print('############################################')\n",
    "            # Get distribution printed\n",
    "            for index, value in classes_counter.items():\n",
    "                print('Training set distribution:')\n",
    "                print('Class: ' + index)\n",
    "                print('Number of images: ' + str(value))\n",
    "\n",
    "        df_updated = pd.DataFrame(new_dataset_dict)\n",
    "        df_updated.to_csv(reduced_csv_path, index=False)\n",
    "\n",
    "    except OSError as e:\n",
    "        print(e)\n",
    "\n",
    "    print(\"Data structure created\")\n",
    "\n",
    "\n",
    "def read_csv_files(train_csv, val_csv):\n",
    "    '''\n",
    "    Read csv files for training and validation\n",
    "    :param train_csv: Path to train csv file\n",
    "    :param val_csv: Path to val csv file\n",
    "    :return: dict train_classes (key: image_name, value: class), dict val_classes (key: image_name, value: class)\n",
    "    '''\n",
    "    train_classes = {}\n",
    "    val_classes = {}\n",
    "    df_train = pd.read_csv(train_csv)\n",
    "    df_val = pd.read_csv(val_csv)\n",
    "\n",
    "    for i, image in df_train.iterrows():\n",
    "        image_class = get_classification(image)\n",
    "        if image_class is not None:\n",
    "            train_classes[image['image']] = image_class\n",
    "\n",
    "    for i, image in df_val.iterrows():\n",
    "        image_class = get_classification(image)\n",
    "        if image_class is not None:\n",
    "            val_classes[image['image']] = image_class\n",
    "\n",
    "    return train_classes, val_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6v43u_6aW24"
   },
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nWQZjMEhabdr"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import exposure, morphology, filters, img_as_ubyte, img_as_float\n",
    "from skimage.color.adapt_rgb import adapt_rgb, each_channel\n",
    "\n",
    "\n",
    "def enlarge_image(img):\n",
    "    '''\n",
    "    Enlarge image with dark border areas\n",
    "    :param img: ndarray, BGR image\n",
    "    :return: ndarray, BGR image\n",
    "    '''\n",
    "    f = np.zeros((700, 700,3), np.uint8)\n",
    "    ax, ay = (700 - img.shape[1]) // 2, (700 - img.shape[0]) // 2\n",
    "    f[ay:img.shape[0] + ay, ax:ax + img.shape[1]] = img\n",
    "    return f\n",
    "\n",
    "\n",
    "def reduce_image(img):\n",
    "    '''\n",
    "    Resize image to size 600x600 and remove dark border areas\n",
    "    :param img: ndarray, BGR image\n",
    "    :return: ndarray, BGR image\n",
    "    '''\n",
    "    ax, ay = (img.shape[1]-600)//2, (img.shape[0] - 600) // 2\n",
    "    f = img[ay:600 + ay, ax:ax + 600]\n",
    "    return f\n",
    "\n",
    "\n",
    "def reduce_mask(img):\n",
    "    '''\n",
    "    Reuce mask size to 600x600\n",
    "    :param img: ndarray, binary image\n",
    "    :return: ndarray, binary image\n",
    "    '''\n",
    "    ax, ay = (img.shape[1]-600)//2, (img.shape[0] - 600) // 2\n",
    "    f = img[ay:600 + ay, ax:ax + 600]\n",
    "    return f\n",
    "\n",
    "\n",
    "def remove_black_border(gray_image):\n",
    "    '''\n",
    "    Remove black border areas\n",
    "    :param gray_image: ndarray, grayscale image\n",
    "    :return: ndarray, binary image\n",
    "    '''\n",
    "    _, mask = cv2.threshold(gray_image, 10, 255, cv2.THRESH_BINARY);\n",
    "    (contours, _) = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    c = max(contours, key=cv2.contourArea)\n",
    "    mask_a = np.zeros((700, 700), np.uint8)\n",
    "    cv2.drawContours(mask_a, [c], -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "    kernel = np.ones((15, 15), np.uint8)\n",
    "    eroded = cv2.erode(mask_a, kernel, iterations=3)\n",
    "    _, mask_a = cv2.threshold(eroded, 10, 255, cv2.THRESH_BINARY);\n",
    "    return mask_a\n",
    "\n",
    "\n",
    "@adapt_rgb(each_channel)\n",
    "def morph_closing_each(image, struct_element):\n",
    "    return morphology.closing(image, struct_element)\n",
    "\n",
    "\n",
    "@adapt_rgb(each_channel)\n",
    "def median_filter_each(image, struct_element):\n",
    "    return filters.median(image, struct_element)\n",
    "\n",
    "\n",
    "structuring_element = morphology.disk(7)\n",
    "\n",
    "\n",
    "def crop_center_rgb(img, cropx, cropy):\n",
    "    '''\n",
    "    Crop image from the center\n",
    "    :param img: ndarray, BGR image\n",
    "    :param cropx: width in int\n",
    "    :param cropy: height in int\n",
    "    :return: ndarray, BGR cropped image\n",
    "    '''\n",
    "    y,x,_ = img.shape\n",
    "    startx = x//2-(cropx//2)\n",
    "    starty = y//2-(cropy//2)\n",
    "    return img[starty:starty+cropy,startx:startx+cropx,:]\n",
    "\n",
    "\n",
    "def noise_removal(img):\n",
    "    '''\n",
    "    Remove noise in the image\n",
    "    :param img: ndarray, BGR image\n",
    "    :return: ndarray, BGR filtered image\n",
    "    '''\n",
    "    img = img_as_float(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    equalized_adapthist = exposure.equalize_adapthist(img)\n",
    "    img_morph_closing = morph_closing_each(equalized_adapthist, structuring_element)\n",
    "    img_filtered = median_filter_each(img_morph_closing, structuring_element)\n",
    "    img_filtered = cv2.cvtColor(img_as_ubyte(img_filtered), cv2.COLOR_RGB2BGR)\n",
    "    return img_filtered\n",
    "\n",
    "\n",
    "# Not used anymore\n",
    "# See https://www.kaggle.com/apacheco/shades-of-gray-color-constancy\n",
    "def shade_of_gray_cc(img, power=6, gamma=None):\n",
    "    \"\"\"\n",
    "    img (numpy array): the original image with format of (h, w, c)\n",
    "    power (int): the degree of norm, 6 is used in reference paper\n",
    "    gamma (float): the value of gamma correction, 2.2 is used in reference paper\n",
    "    \"\"\"\n",
    "    img_dtype = img.dtype\n",
    "\n",
    "    if gamma is not None:\n",
    "        img = img.astype('uint8')\n",
    "        look_up_table = np.ones((256, 1), dtype='uint8') * 0\n",
    "        for i in range(256):\n",
    "            look_up_table[i][0] = 255 * pow(i / 255, 1 / gamma)\n",
    "        img = cv2.LUT(img, look_up_table)\n",
    "\n",
    "    img = img.astype('float32')\n",
    "    img_power = np.power(img, power)\n",
    "    rgb_vec = np.power(np.mean(img_power, (0, 1)), 1 / power)\n",
    "    rgb_norm = np.sqrt(np.sum(np.power(rgb_vec, 2.0)))\n",
    "    rgb_vec = rgb_vec / rgb_norm\n",
    "    rgb_vec = 1 / (rgb_vec * np.sqrt(3))\n",
    "    img = np.multiply(img, rgb_vec)\n",
    "\n",
    "    # Andrew Anikin suggestion\n",
    "    img = np.clip(img, a_min=0, a_max=255)\n",
    "\n",
    "    return img.astype(img_dtype)\n",
    "\n",
    "\n",
    "def preprocess_image(img):\n",
    "    '''\n",
    "    Preprocess image\n",
    "    :param img: ndarray, BGR image\n",
    "    :return:  ndarray, BGR image\n",
    "    '''\n",
    "    img = noise_removal(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def crop_image(img):\n",
    "    '''\n",
    "    Remove dark border areas and crop image\n",
    "    :param img: ndarray, BGR image\n",
    "    :return: ndarray, BGR image\n",
    "    '''\n",
    "    img = cv2.resize(img, (600, 600))\n",
    "    inpaint_image = enlarge_image(img)\n",
    "\n",
    "    # Remove black border\n",
    "    gray = cv2.cvtColor(inpaint_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    mask = remove_black_border(gray)\n",
    "    #mean = cv2.mean(inpaint_image, mask)\n",
    "    mask = reduce_mask(mask)\n",
    "    inpaint_image = reduce_image(inpaint_image)\n",
    "    inpaint_image[mask == 0] = 0\n",
    "\n",
    "    coords = cv2.findNonZero(mask)\n",
    "    x, y, w, h = cv2.boundingRect(coords)\n",
    "    inpaint_image = inpaint_image[y:y + h, x:x + w]\n",
    "    inpaint_image = cv2.resize(inpaint_image, (600, 600))\n",
    "    # inpaint_image = shade_of_gray_cc(inpaint_image)\n",
    "\n",
    "    # Crop from the center the image if the borders are black\n",
    "    gray_img = cv2.cvtColor(inpaint_image, cv2.COLOR_BGR2GRAY)\n",
    "    if gray_img[0][0] < 10 and gray_img[0][-1] < 10 and gray_img[-1][0] < 10 and gray_img[-1][-1] < 10:\n",
    "        inpaint_image = cv2.resize(crop_center_rgb(inpaint_image, 400, 400), (600,600))\n",
    "    return inpaint_image\n",
    "\n",
    "\n",
    "def preprocess_dataset(dataset_path, dataset_csv_path, preprocessed_dataset_path):\n",
    "    '''\n",
    "    Preprocess training and validation dataset\n",
    "    :param dataset_path: Path to dataset\n",
    "    :param dataset_csv_path: Path to training csv file\n",
    "    :param val_csv_path: Path to validation csv file\n",
    "    :param preprocessed_dataset_path: Path where to save preprocessed  images\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    df_train = pd.read_csv(dataset_csv_path)\n",
    "\n",
    "    print('Start of preprocessing step of dataset ')\n",
    "    for i, image in df_train.iterrows():\n",
    "        img = cv2.imread(dataset_path + image['image']+'.jpg', cv2.IMREAD_COLOR)\n",
    "        img = preprocess_image(img)\n",
    "        cv2.imwrite(preprocessed_dataset_path + image['image']+'.jpg', img)\n",
    "        print(str(i) + ': Preprocessed image ' + image['image'])\n",
    "    print('Finished preprocess step of dataset')\n",
    "    print('preprocessed images saved in ' + preprocessed_dataset_path)\n",
    "    print('Finished script')\n",
    "\n",
    "\n",
    "def crop_dataset(dataset_path, dataset_csv_path):\n",
    "    '''\n",
    "    Crop training and validation dataset\n",
    "    :param dataset_path: Path to training dataset\n",
    "    :param dataset_csv_path: Path to training csv file\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    df_dataset = pd.read_csv(dataset_csv_path)\n",
    "\n",
    "    print('Start of dataset cropping step')\n",
    "    for i, image in df_dataset.iterrows():\n",
    "        img = cv2.imread(dataset_path + image['image']+'.jpg', cv2.IMREAD_COLOR)\n",
    "        img = crop_image(img)\n",
    "        cv2.imwrite(dataset_path + image['image']+'.jpg', img)\n",
    "        print(str(i) + ': Cropped image ' + image['image'])\n",
    "    print('Finished cropping step of dataset')\n",
    "    print('cropped  images saved in ' + dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ej6PF4L1bKXu"
   },
<<<<<<< HEAD
   "source": [
    "# Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ThjAlc-TauKj"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(true_labels, predicted_labels, class_labels):\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title('Confusion matrix')\n",
    "    sns.heatmap(conf_matrix.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "                xticklabels=sorted(class_labels), yticklabels=sorted(class_labels))\n",
    "    plt.xlabel('true label')\n",
    "    plt.ylabel('predicted label')\n",
    "    plt.draw()\n",
    "    plt.tight_layout()\n",
    "    plt.show();\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_hist(hist):\n",
    "    plt.plot(hist.history[\"accuracy\"])\n",
    "    plt.plot(hist.history[\"val_accuracy\"])\n",
    "    plt.title(\"model accuracy\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBvBt0qna22e"
   },
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q-_iXPyOa69K"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, \\\n",
    "                            recall_score, accuracy_score, classification_report\n",
    "import pandas as pd"
   ]
=======
   "source": []
>>>>>>> a922132d65588c9732184eec27866d39fadad964
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zErueg7ubQmP"
   },
   "outputs": [],
   "source": [
    "# Set paths\n",
    "train_set_path = \"/content/drive/MyDrive/uni/ism/pastukai/data/images/training_set/\"\n",
    "val_set_path = \"/content/drive/MyDrive/uni/ism/pastukai/data/images/val_set/\"\n",
    "# Preprocessed Paths\n",
    "# preprocessed_train_set_path = \"/content/drive/MyDrive/uni/ism/pastukai/data/images/preprocessed_training_set/\"\n",
    "# preprocessed_val_set_path = \"/content/drive/MyDrive/uni/ism/pastukai/data/images/preprocessed_val_set/\"\n",
    "\n",
    "dataset_path = '/content/drive/MyDrive/uni/ism/pastukai/temp/dataset/'\n",
    "train_csv = '/content/drive/MyDrive/uni/ism/pastukai/data/groundtruth_train.csv'\n",
    "train_reduced_csv = '/content/drive/MyDrive/uni/ism/pastukai/data/reduced_groundtruth_train.csv'\n",
    "val_csv = '/content/drive/MyDrive/uni/ism/pastukai/data/groundtruth_val.csv'\n",
    "val_reduced_csv = '/content/drive/MyDrive/uni/ism/pastukai/data/reduced_groundtruth_val.csv'\n",
    "\n",
    "# Preprocess data\n",
    "do_preprocess = False\n",
    "sample_number=1000\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(train_set_path, exist_ok=True)\n",
    "os.makedirs(val_set_path, exist_ok=True)\n",
    "\n",
    "# os.makedirs(preprocessed_train_set_path, exist_ok=True)\n",
    "# os.makedirs(preprocessed_val_set_path, exist_ok=True)\n",
    "\n",
    "\n",
    "NUM_CLASSES = 8\n",
    "IMG_SIZE = 224\n",
    "dropout_rate = 0.4\n",
    "batch_size = 15\n",
    "epochs = 40\n",
    "learning_rate= 0.01\n",
    "print('Build directory structure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "GncDsbkokP9y"
   },
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "prepare_dataset(dataset_path,train_set_path, \n",
    "                        train_csv, train_reduced_csv, sample_number, validation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x4Sfl-xBrZ8z"
   },
   "outputs": [],
   "source": [
    "# Prepare validation data\n",
    "prepare_dataset(dataset_path,val_set_path, \n",
    "                        val_csv, val_reduced_csv, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5NnE5vqm2qmG"
   },
   "outputs": [],
   "source": [
    "# Skip this step if you intend to use the last dataset split\n",
    "# Remove black border from training  images \n",
    "crop_dataset(train_set_path, train_reduced_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XPEhoZbYqfUQ"
   },
   "outputs": [],
   "source": [
    "# Skip this step if you intend to use the last dataset split\n",
    "# Remove black border from validation  images \n",
    "crop_dataset(val_set_path, val_reduced_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1UC1Gd1fkmMo"
   },
   "outputs": [],
   "source": [
    "# Preprocess data and save preprocessed training images\n",
    "if do_preprocess:\n",
    "    preprocess_dataset(train_set_path, train_reduced_csv, preprocessed_train_set_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nzTofEHcqz_3"
   },
   "outputs": [],
   "source": [
    "# Preprocess data and save preprocessed validation images\n",
    "if do_preprocess:\n",
    "    preprocess_dataset(val_set_path, val_reduced_csv, preprocessed_val_set_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5_qKOYe-1aWr"
   },
   "outputs": [],
   "source": [
    "# Read dataframes\n",
    "train_df, val_df = read_csv_files(train_reduced_csv, val_reduced_csv)\n",
    "\n",
    "new_train = {}\n",
    "new_val = {}\n",
    "\n",
    "for key,value in train_df.items():\n",
    "  new_train[key+'.jpg'] = value\n",
    "\n",
    "for key,value in val_df.items():\n",
    "  new_val[key+'.jpg'] = value\n",
    "\n",
    "train_df = new_train\n",
    "val_df = new_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XWgaGTSFBZqZ"
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(list(train_df.items()), columns=['image_name','class'])\n",
    "val_df = pd.DataFrame(list(val_df.items()), columns=['image_name','class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dygEMtk7oDrC"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from keras import optimizers\n",
    "from keras.applications import MobileNet\n",
    "from keras.layers import Dense,GlobalAveragePooling2D,Flatten,Dropout,BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D,Input\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "\n",
    "\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "def top_2_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=2)\n",
    "\n",
    "def build_effnet():\n",
    "  input_shape = (IMG_SIZE,IMG_SIZE,3)\n",
    "  conv_base = EfficientNetB3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "  model = models.Sequential()\n",
    "  model.add(conv_base)\n",
    "  model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
    "  if dropout_rate > 0:\n",
    "      model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
    "  model.add(layers.Dense(NUM_CLASSES, activation='softmax', name=\"fc_out\"))\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])\n",
    "  model.summary()\n",
    "  return model\n",
    "\n",
    "def build_mobilenet():\n",
    "  base_model=MobileNet(weights='imagenet',include_top=False,input_shape=(IMG_SIZE, IMG_SIZE, 3)) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "\n",
    "  x=base_model.output\n",
    "  x=GlobalAveragePooling2D()(x)\n",
    "  x=Dropout(0.4)(x)\n",
    "\n",
    "  x=Dense(300,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better result\n",
    "  x=Dropout(0.4)(x)\n",
    "  x=BatchNormalization()(x)\n",
    "  x=Dense(100,activation='relu')(x) #dense layer 2\n",
    "  x=Dropout(0.4)(x)\n",
    "\n",
    "  x=Dense(50,activation='relu')(x) #dense layer 3\n",
    "  preds=Dense(NUM_CLASSES,activation='softmax')(x) #final layer with softmax activation\n",
    "\n",
    "  model=Model(inputs=base_model.input,outputs=preds)\n",
    "  print(len(model.layers[:]))\n",
    "  for layer in model.layers[:85]:\n",
    "    layer.trainable=False\n",
    "  for layer in model.layers[85:]:\n",
    "    layer.trainable=True\n",
    "  model.summary()\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=learning_rate),\n",
    "              metrics=[categorical_accuracy, top_2_accuracy, top_3_accuracy])\n",
    "  return model\n",
    "\n",
    "def build_resnet():\n",
    "  baseModel = ResNet50(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "  headModel = baseModel.output\n",
    "  headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "  headModel = Flatten(name=\"flatten\")(headModel)\n",
    "  headModel = Dense(256, activation=\"relu\")(headModel)\n",
    "  headModel = Dropout(0.5)(headModel)\n",
    "  headModel = Dense(NUM_CLASSES, activation=\"softmax\")(headModel)\n",
    "\n",
    "  model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "  model.summary()\n",
    "  for layer in baseModel.layers:\n",
    "\t  layer.trainable = False\n",
    "  opt = Adam(lr=learning_rate, decay=learning_rate / epochs)\n",
    "  model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[categorical_accuracy, top_2_accuracy, top_3_accuracy])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G3Uh29DloTFq"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_iterator = datagen.flow_from_dataframe(train_df,\n",
    "                                            directory=train_set_path,\n",
    "                                            x_col='image_name',\n",
    "                                            y_col='class',\n",
    "                                            target_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                            batch_size=batch_size,\n",
    "                                            color_mode='rgb',\n",
    "                                            class_mode='categorical')\n",
    "\n",
    "val_iterator = datagen.flow_from_dataframe(val_df,\n",
    "                                            directory=val_set_path,\n",
    "                                            x_col='image_name',\n",
    "                                            y_col='class',\n",
    "                                            target_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                            batch_size=batch_size,\n",
    "                                            color_mode='rgb',\n",
    "                                            class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JL6RUZ09Nf_2"
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"/content/drive/MyDrive/uni/ism/pastukai/model.h5\", monitor='val_top_3_accuracy', verbose=1,\n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "# Reduce the learning rate as the learning stagnates\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_top_3_accuracy', factor=0.5, patience=2,\n",
    "                              verbose=1, mode='max', min_lr=0.00001)\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_lr]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = build_model_mobilenet()\n",
    "history = model.fit(train_iterator,\n",
    "                           steps_per_epoch= train_iterator.samples // batch_size,\n",
    "                           epochs=epochs,\n",
    "                           validation_data=val_iterator,\n",
    "                           validation_steps= val_iterator.samples // batch_size,\n",
<<<<<<< HEAD
    "                           verbose=1)"
   ]
=======
    "                           verbose=1,\n",
    "                           callbacks=callbacks_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
>>>>>>> a922132d65588c9732184eec27866d39fadad964
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3jAwuaeRw60X"
   },
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_x = range(len(acc))\n",
    "\n",
    "plt.plot(epochs_x, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs_x, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs_x, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs_x, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6YpriW9rlg-6"
   },
   "outputs": [],
   "source": [
    "model.save(\"/content/drive/MyDrive/uni/ism/pastukai/model.h5\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "T6H7YKwJVBAi",
    "c6v43u_6aW24",
    "Ej6PF4L1bKXu"
   ],
   "name": "skin_lesion.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
